{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install nltk\n","execution_count":2,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: nltk in /srv/conda/envs/notebook/lib/python3.6/site-packages (3.6.3)\nRequirement already satisfied: tqdm in /srv/conda/envs/notebook/lib/python3.6/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: joblib in /srv/conda/envs/notebook/lib/python3.6/site-packages (from nltk) (1.0.1)\nRequirement already satisfied: regex in /srv/conda/envs/notebook/lib/python3.6/site-packages (from nltk) (2021.9.30)\nRequirement already satisfied: click in /srv/conda/envs/notebook/lib/python3.6/site-packages (from nltk) (8.0.1)\nRequirement already satisfied: importlib-metadata in /srv/conda/envs/notebook/lib/python3.6/site-packages (from click->nltk) (4.8.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from importlib-metadata->click->nltk) (3.10.0.0)\nRequirement already satisfied: zipp>=0.5 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from importlib-metadata->click->nltk) (3.5.0)\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download()","execution_count":4,"outputs":[{"output_type":"stream","text":"NLTK Downloader\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\nDownloader> d\n\nDownload which package (l=list; x=cancel)?\n  Identifier> l\nPackages:\n  [ ] abc................. Australian Broadcasting Commission 2006\n  [ ] alpino.............. Alpino Dutch Treebank\n  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n  [ ] basque_grammars..... Grammars for Basque\n  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n                           Extraction Systems in Biology)\n  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n  [ ] book_grammars....... Grammars from NLTK Book\n  [ ] brown............... Brown Corpus\n  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n  [ ] cess_cat............ CESS-CAT Treebank\n  [ ] cess_esp............ CESS-ESP Treebank\n  [ ] chat80.............. Chat-80 Data Files\n  [ ] city_database....... City Database\n  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n  [ ] comparative_sentences Comparative Sentence Dataset\n  [ ] comtrans............ ComTrans Corpus Sample\n  [ ] conll2000........... CONLL 2000 Chunking Corpus\n  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\nHit Enter to continue: \n  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n                           and Basque Subset)\n  [ ] crubadan............ Crubadan Corpus\n  [ ] dependency_treebank. Dependency Parsed Treebank\n  [ ] dolch............... Dolch Word List\n  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n                           Corpus\n  [ ] floresta............ Portuguese Treebank\n  [ ] framenet_v15........ FrameNet 1.5\n  [ ] framenet_v17........ FrameNet 1.7\n  [ ] gazetteers.......... Gazeteer Lists\n  [ ] genesis............. Genesis Corpus\n  [ ] gutenberg........... Project Gutenberg Selections\n  [ ] ieer................ NIST IE-ER DATA SAMPLE\n  [ ] inaugural........... C-Span Inaugural Address Corpus\n  [ ] indian.............. Indian Language POS-Tagged Corpus\n  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n                           ChaSen format)\n  [ ] kimmo............... PC-KIMMO Data Files\n  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n  [ ] large_grammars...... Large context-free and feature-based grammars\n                           for parser comparison\nHit Enter to continue: \n  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n                           part-of-speech tags\n  [ ] machado............. Machado de Assis -- Obra Completa\n  [ ] masc_tagged......... MASC Tagged Corpus\n  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n  [ ] moses_sample........ Moses Sample Models\n  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n                           2015) subset of the Paraphrase Database.\n  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n  [ ] nombank.1.0......... NomBank Corpus 1.0\n  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n  [ ] nps_chat............ NPS Chat\n  [ ] omw................. Open Multilingual Wordnet\n  [ ] opinion_lexicon..... Opinion Lexicon\n  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n  [ ] paradigms........... Paradigm Corpus\n  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n                           Evaluation Shared Task\nHit Enter to continue: \n  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n                           character properties in Perl\n  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n  [ ] pl196x.............. Polish language of the XX century sixties\n  [ ] porter_test......... Porter Stemmer Test Files\n  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n  [ ] problem_reports..... Problem Report Corpus\n  [ ] product_reviews_1... Product Reviews (5 Products)\n  [ ] product_reviews_2... Product Reviews (9 Products)\n  [ ] propbank............ Proposition Bank Corpus 1.0\n  [ ] pros_cons........... Pros and Cons\n  [ ] ptb................. Penn Treebank\n  [ ] punkt............... Punkt Tokenizer Models\n  [ ] qc.................. Experimental Data for Question Classification\n  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n                           version\n  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n                           Portuguesa)\n  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n  [ ] sample_grammars..... Sample Grammars\n  [ ] semcor.............. SemCor 3.0\nHit Enter to continue: \n  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n  [ ] sentiwordnet........ SentiWordNet\n  [ ] shakespeare......... Shakespeare XML Corpus Sample\n  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n  [ ] smultron............ SMULTRON Corpus Sample\n  [ ] snowball_data....... Snowball Data\n  [ ] spanish_grammars.... Grammars for Spanish\n  [ ] state_union......... C-Span State of the Union Address Corpus\n  [ ] stopwords........... Stopwords Corpus\n  [ ] subjectivity........ Subjectivity Dataset v1.0\n  [ ] swadesh............. Swadesh Wordlists\n  [ ] switchboard......... Switchboard Corpus Sample\n  [ ] tagsets............. Help on Tagsets\n  [ ] timit............... TIMIT Corpus Sample\n  [ ] toolbox............. Toolbox Sample Files\n  [ ] treebank............ Penn Treebank Sample\n  [ ] twitter_samples..... Twitter Samples\n  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n                           (Unicode Version)\n  [ ] udhr................ Universal Declaration of Human Rights Corpus\nHit Enter to continue: \n  [ ] unicode_samples..... Unicode Samples\n  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n  [ ] vader_lexicon....... VADER Sentiment Lexicon\n  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n  [ ] webtext............. Web Text Corpus\n  [ ] wmt15_eval.......... Evaluation data from WMT15\n  [ ] word2vec_sample..... Word2Vec Sample\n  [ ] wordnet............. WordNet\n  [ ] wordnet_ic.......... WordNet-InfoContent\n  [ ] words............... Word Lists\n  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n                           English Prose\n\nCollections:\n  [ ] all-corpora......... All the corpora\n  [ ] all-nltk............ All packages available on nltk_data gh-pages\n                           branch\n  [ ] all................. All packages\n  [ ] book................ Everything used in the NLTK Book\n  [ ] popular............. Popular packages\nHit Enter to continue: \n  [ ] tests............... Packages for running tests\n  [ ] third-party......... Third-party data packages\n\n([*] marks installed packages)\n\nDownload which package (l=list; x=cancel)?\n  Identifier> *\n","name":"stdout"},{"output_type":"stream","text":"    Error loading *: Package '*' not found in index\n","name":"stderr"},{"output_type":"stream","text":"\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\nDownloader> d\n\nDownload which package (l=list; x=cancel)?\n  Identifier> l\nPackages:\n  [ ] abc................. Australian Broadcasting Commission 2006\n  [ ] alpino.............. Alpino Dutch Treebank\n  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n  [ ] basque_grammars..... Grammars for Basque\n  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n                           Extraction Systems in Biology)\n  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n  [ ] book_grammars....... Grammars from NLTK Book\n  [ ] brown............... Brown Corpus\n  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n  [ ] cess_cat............ CESS-CAT Treebank\n  [ ] cess_esp............ CESS-ESP Treebank\n  [ ] chat80.............. Chat-80 Data Files\n  [ ] city_database....... City Database\n  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n  [ ] comparative_sentences Comparative Sentence Dataset\n  [ ] comtrans............ ComTrans Corpus Sample\n  [ ] conll2000........... CONLL 2000 Chunking Corpus\n  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\nHit Enter to continue: \n  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n                           and Basque Subset)\n  [ ] crubadan............ Crubadan Corpus\n  [ ] dependency_treebank. Dependency Parsed Treebank\n  [ ] dolch............... Dolch Word List\n  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n                           Corpus\n  [ ] floresta............ Portuguese Treebank\n  [ ] framenet_v15........ FrameNet 1.5\n  [ ] framenet_v17........ FrameNet 1.7\n  [ ] gazetteers.......... Gazeteer Lists\n  [ ] genesis............. Genesis Corpus\n  [ ] gutenberg........... Project Gutenberg Selections\n  [ ] ieer................ NIST IE-ER DATA SAMPLE\n  [ ] inaugural........... C-Span Inaugural Address Corpus\n  [ ] indian.............. Indian Language POS-Tagged Corpus\n  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n                           ChaSen format)\n  [ ] kimmo............... PC-KIMMO Data Files\n  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n  [ ] large_grammars...... Large context-free and feature-based grammars\n                           for parser comparison\nHit Enter to continue: \n  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n                           part-of-speech tags\n  [ ] machado............. Machado de Assis -- Obra Completa\n  [ ] masc_tagged......... MASC Tagged Corpus\n  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n  [ ] moses_sample........ Moses Sample Models\n  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n                           2015) subset of the Paraphrase Database.\n  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n  [ ] nombank.1.0......... NomBank Corpus 1.0\n  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n  [ ] nps_chat............ NPS Chat\n  [ ] omw................. Open Multilingual Wordnet\n  [ ] opinion_lexicon..... Opinion Lexicon\n  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n  [ ] paradigms........... Paradigm Corpus\n  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n                           Evaluation Shared Task\nHit Enter to continue: \n  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n                           character properties in Perl\n  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n  [ ] pl196x.............. Polish language of the XX century sixties\n  [ ] porter_test......... Porter Stemmer Test Files\n  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n  [ ] problem_reports..... Problem Report Corpus\n  [ ] product_reviews_1... Product Reviews (5 Products)\n  [ ] product_reviews_2... Product Reviews (9 Products)\n  [ ] propbank............ Proposition Bank Corpus 1.0\n  [ ] pros_cons........... Pros and Cons\n  [ ] ptb................. Penn Treebank\n  [ ] punkt............... Punkt Tokenizer Models\n  [ ] qc.................. Experimental Data for Question Classification\n  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n                           version\n  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n                           Portuguesa)\n  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n  [ ] sample_grammars..... Sample Grammars\n  [ ] semcor.............. SemCor 3.0\nHit Enter to continue: \n  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n  [ ] sentiwordnet........ SentiWordNet\n  [ ] shakespeare......... Shakespeare XML Corpus Sample\n  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n  [ ] smultron............ SMULTRON Corpus Sample\n  [ ] snowball_data....... Snowball Data\n  [ ] spanish_grammars.... Grammars for Spanish\n  [ ] state_union......... C-Span State of the Union Address Corpus\n  [ ] stopwords........... Stopwords Corpus\n  [ ] subjectivity........ Subjectivity Dataset v1.0\n  [ ] swadesh............. Swadesh Wordlists\n  [ ] switchboard......... Switchboard Corpus Sample\n  [ ] tagsets............. Help on Tagsets\n  [ ] timit............... TIMIT Corpus Sample\n  [ ] toolbox............. Toolbox Sample Files\n  [ ] treebank............ Penn Treebank Sample\n  [ ] twitter_samples..... Twitter Samples\n  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n                           (Unicode Version)\n  [ ] udhr................ Universal Declaration of Human Rights Corpus\nHit Enter to continue: \n  [ ] unicode_samples..... Unicode Samples\n  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n  [ ] vader_lexicon....... VADER Sentiment Lexicon\n  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n  [ ] webtext............. Web Text Corpus\n  [ ] wmt15_eval.......... Evaluation data from WMT15\n  [ ] word2vec_sample..... Word2Vec Sample\n  [ ] wordnet............. WordNet\n  [ ] wordnet_ic.......... WordNet-InfoContent\n  [ ] words............... Word Lists\n  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n                           English Prose\n\nCollections:\n  [ ] all-corpora......... All the corpora\n  [ ] all-nltk............ All packages available on nltk_data gh-pages\n                           branch\n  [ ] all................. All packages\n  [ ] book................ Everything used in the NLTK Book\n  [ ] popular............. Popular packages\nHit Enter to continue: \n  [ ] tests............... Packages for running tests\n  [ ] third-party......... Third-party data packages\n\n([*] marks installed packages)\n\nDownload which package (l=list; x=cancel)?\n  Identifier> h\n","name":"stdout"},{"output_type":"stream","text":"    Error loading h: Package 'h' not found in index\n","name":"stderr"},{"output_type":"stream","text":"\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\nDownloader> h\n\nCommands:\n  d) Download a package or collection     u) Update out of date packages\n  l) List packages & collections          h) Help\n  c) View & Modify Configuration          q) Quit\n\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\nDownloader> d\n\nDownload which package (l=list; x=cancel)?\n  Identifier> x\n\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\nDownloader> d\n\nDownload which package (l=list; x=cancel)?\n  Identifier> l\nPackages:\n  [ ] abc................. Australian Broadcasting Commission 2006\n  [ ] alpino.............. Alpino Dutch Treebank\n  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n  [ ] basque_grammars..... Grammars for Basque\n  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n                           Extraction Systems in Biology)\n  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n  [ ] book_grammars....... Grammars from NLTK Book\n  [ ] brown............... Brown Corpus\n  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n  [ ] cess_cat............ CESS-CAT Treebank\n  [ ] cess_esp............ CESS-ESP Treebank\n  [ ] chat80.............. Chat-80 Data Files\n  [ ] city_database....... City Database\n  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n  [ ] comparative_sentences Comparative Sentence Dataset\n  [ ] comtrans............ ComTrans Corpus Sample\n  [ ] conll2000........... CONLL 2000 Chunking Corpus\n  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\nHit Enter to continue: \n  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n                           and Basque Subset)\n  [ ] crubadan............ Crubadan Corpus\n  [ ] dependency_treebank. Dependency Parsed Treebank\n  [ ] dolch............... Dolch Word List\n  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n                           Corpus\n  [ ] floresta............ Portuguese Treebank\n  [ ] framenet_v15........ FrameNet 1.5\n  [ ] framenet_v17........ FrameNet 1.7\n  [ ] gazetteers.......... Gazeteer Lists\n  [ ] genesis............. Genesis Corpus\n  [ ] gutenberg........... Project Gutenberg Selections\n  [ ] ieer................ NIST IE-ER DATA SAMPLE\n  [ ] inaugural........... C-Span Inaugural Address Corpus\n  [ ] indian.............. Indian Language POS-Tagged Corpus\n  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n                           ChaSen format)\n  [ ] kimmo............... PC-KIMMO Data Files\n  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n  [ ] large_grammars...... Large context-free and feature-based grammars\n                           for parser comparison\nHit Enter to continue: \n  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n                           part-of-speech tags\n  [ ] machado............. Machado de Assis -- Obra Completa\n  [ ] masc_tagged......... MASC Tagged Corpus\n  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n  [ ] moses_sample........ Moses Sample Models\n  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n                           2015) subset of the Paraphrase Database.\n  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n  [ ] nombank.1.0......... NomBank Corpus 1.0\n  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n  [ ] nps_chat............ NPS Chat\n  [ ] omw................. Open Multilingual Wordnet\n  [ ] opinion_lexicon..... Opinion Lexicon\n  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n  [ ] paradigms........... Paradigm Corpus\n  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n                           Evaluation Shared Task\nHit Enter to continue: \n  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n                           character properties in Perl\n  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n  [ ] pl196x.............. Polish language of the XX century sixties\n  [ ] porter_test......... Porter Stemmer Test Files\n  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n  [ ] problem_reports..... Problem Report Corpus\n  [ ] product_reviews_1... Product Reviews (5 Products)\n  [ ] product_reviews_2... Product Reviews (9 Products)\n  [ ] propbank............ Proposition Bank Corpus 1.0\n  [ ] pros_cons........... Pros and Cons\n  [ ] ptb................. Penn Treebank\n  [ ] punkt............... Punkt Tokenizer Models\n  [ ] qc.................. Experimental Data for Question Classification\n  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n                           version\n  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n                           Portuguesa)\n  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n  [ ] sample_grammars..... Sample Grammars\n  [ ] semcor.............. SemCor 3.0\nHit Enter to continue: \n  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n  [ ] sentiwordnet........ SentiWordNet\n  [ ] shakespeare......... Shakespeare XML Corpus Sample\n  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n  [ ] smultron............ SMULTRON Corpus Sample\n  [ ] snowball_data....... Snowball Data\n  [ ] spanish_grammars.... Grammars for Spanish\n  [ ] state_union......... C-Span State of the Union Address Corpus\n  [ ] stopwords........... Stopwords Corpus\n  [ ] subjectivity........ Subjectivity Dataset v1.0\n  [ ] swadesh............. Swadesh Wordlists\n  [ ] switchboard......... Switchboard Corpus Sample\n  [ ] tagsets............. Help on Tagsets\n  [ ] timit............... TIMIT Corpus Sample\n  [ ] toolbox............. Toolbox Sample Files\n  [ ] treebank............ Penn Treebank Sample\n  [ ] twitter_samples..... Twitter Samples\n  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n                           (Unicode Version)\n  [ ] udhr................ Universal Declaration of Human Rights Corpus\nHit Enter to continue: \n  [ ] unicode_samples..... Unicode Samples\n  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n  [ ] vader_lexicon....... VADER Sentiment Lexicon\n  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n  [ ] webtext............. Web Text Corpus\n  [ ] wmt15_eval.......... Evaluation data from WMT15\n  [ ] word2vec_sample..... Word2Vec Sample\n  [ ] wordnet............. WordNet\n  [ ] wordnet_ic.......... WordNet-InfoContent\n  [ ] words............... Word Lists\n  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n                           English Prose\n\nCollections:\n  [ ] all-corpora......... All the corpora\n  [ ] all-nltk............ All packages available on nltk_data gh-pages\n                           branch\n  [ ] all................. All packages\n  [ ] book................ Everything used in the NLTK Book\n  [ ] popular............. Popular packages\nHit Enter to continue: \n  [ ] tests............... Packages for running tests\n  [ ] third-party......... Third-party data packages\n\n([*] marks installed packages)\n\nDownload which package (l=list; x=cancel)?\n  Identifier> u\n","name":"stdout"},{"output_type":"stream","text":"    Error loading u: Package 'u' not found in index\n","name":"stderr"},{"output_type":"stream","text":"\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\nDownloader> u\n\nNothing to update.\n\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\nDownloader> d\n\nDownload which package (l=list; x=cancel)?\n  Identifier> all\n","name":"stdout"},{"output_type":"stream","text":"    Downloading collection 'all'\n       | \n       | Downloading package abc to /home/jovyan/nltk_data...\n       |   Unzipping corpora/abc.zip.\n       | Downloading package alpino to /home/jovyan/nltk_data...\n       |   Unzipping corpora/alpino.zip.\n       | Downloading package biocreative_ppi to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/biocreative_ppi.zip.\n       | Downloading package brown to /home/jovyan/nltk_data...\n       |   Unzipping corpora/brown.zip.\n       | Downloading package brown_tei to /home/jovyan/nltk_data...\n       |   Unzipping corpora/brown_tei.zip.\n       | Downloading package cess_cat to /home/jovyan/nltk_data...\n       |   Unzipping corpora/cess_cat.zip.\n       | Downloading package cess_esp to /home/jovyan/nltk_data...\n       |   Unzipping corpora/cess_esp.zip.\n       | Downloading package chat80 to /home/jovyan/nltk_data...\n       |   Unzipping corpora/chat80.zip.\n       | Downloading package city_database to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/city_database.zip.\n       | Downloading package cmudict to /home/jovyan/nltk_data...\n       |   Unzipping corpora/cmudict.zip.\n       | Downloading package comparative_sentences to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/comparative_sentences.zip.\n       | Downloading package comtrans to /home/jovyan/nltk_data...\n       | Downloading package conll2000 to /home/jovyan/nltk_data...\n       |   Unzipping corpora/conll2000.zip.\n       | Downloading package conll2002 to /home/jovyan/nltk_data...\n       |   Unzipping corpora/conll2002.zip.\n       | Downloading package conll2007 to /home/jovyan/nltk_data...\n       | Downloading package crubadan to /home/jovyan/nltk_data...\n       |   Unzipping corpora/crubadan.zip.\n       | Downloading package dependency_treebank to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/dependency_treebank.zip.\n       | Downloading package dolch to /home/jovyan/nltk_data...\n       |   Unzipping corpora/dolch.zip.\n       | Downloading package europarl_raw to /home/jovyan/nltk_data...\n       |   Unzipping corpora/europarl_raw.zip.\n       | Downloading package floresta to /home/jovyan/nltk_data...\n       |   Unzipping corpora/floresta.zip.\n       | Downloading package framenet_v15 to /home/jovyan/nltk_data...\n       |   Unzipping corpora/framenet_v15.zip.\n       | Downloading package framenet_v17 to /home/jovyan/nltk_data...\n       |   Unzipping corpora/framenet_v17.zip.\n       | Downloading package gazetteers to /home/jovyan/nltk_data...\n       |   Unzipping corpora/gazetteers.zip.\n       | Downloading package genesis to /home/jovyan/nltk_data...\n       |   Unzipping corpora/genesis.zip.\n       | Downloading package gutenberg to /home/jovyan/nltk_data...\n       |   Unzipping corpora/gutenberg.zip.\n       | Downloading package ieer to /home/jovyan/nltk_data...\n       |   Unzipping corpora/ieer.zip.\n       | Downloading package inaugural to /home/jovyan/nltk_data...\n       |   Unzipping corpora/inaugural.zip.\n       | Downloading package indian to /home/jovyan/nltk_data...\n       |   Unzipping corpora/indian.zip.\n       | Downloading package jeita to /home/jovyan/nltk_data...\n       | Downloading package kimmo to /home/jovyan/nltk_data...\n       |   Unzipping corpora/kimmo.zip.\n       | Downloading package knbc to /home/jovyan/nltk_data...\n       | Downloading package lin_thesaurus to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/lin_thesaurus.zip.\n       | Downloading package mac_morpho to /home/jovyan/nltk_data...\n       |   Unzipping corpora/mac_morpho.zip.\n       | Downloading package machado to /home/jovyan/nltk_data...\n       | Downloading package masc_tagged to /home/jovyan/nltk_data...\n       | Downloading package moses_sample to /home/jovyan/nltk_data...\n       |   Unzipping models/moses_sample.zip.\n       | Downloading package movie_reviews to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/movie_reviews.zip.\n       | Downloading package names to /home/jovyan/nltk_data...\n       |   Unzipping corpora/names.zip.\n       | Downloading package nombank.1.0 to /home/jovyan/nltk_data...\n       | Downloading package nps_chat to /home/jovyan/nltk_data...\n       |   Unzipping corpora/nps_chat.zip.\n       | Downloading package omw to /home/jovyan/nltk_data...\n       |   Unzipping corpora/omw.zip.\n       | Downloading package opinion_lexicon to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/opinion_lexicon.zip.\n       | Downloading package paradigms to /home/jovyan/nltk_data...\n       |   Unzipping corpora/paradigms.zip.\n       | Downloading package pil to /home/jovyan/nltk_data...\n       |   Unzipping corpora/pil.zip.\n       | Downloading package pl196x to /home/jovyan/nltk_data...\n       |   Unzipping corpora/pl196x.zip.\n       | Downloading package ppattach to /home/jovyan/nltk_data...\n       |   Unzipping corpora/ppattach.zip.\n       | Downloading package problem_reports to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/problem_reports.zip.\n       | Downloading package propbank to /home/jovyan/nltk_data...\n       | Downloading package ptb to /home/jovyan/nltk_data...\n       |   Unzipping corpora/ptb.zip.\n       | Downloading package product_reviews_1 to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/product_reviews_1.zip.\n       | Downloading package product_reviews_2 to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/product_reviews_2.zip.\n       | Downloading package pros_cons to /home/jovyan/nltk_data...\n       |   Unzipping corpora/pros_cons.zip.\n       | Downloading package qc to /home/jovyan/nltk_data...\n       |   Unzipping corpora/qc.zip.\n       | Downloading package reuters to /home/jovyan/nltk_data...\n       | Downloading package rte to /home/jovyan/nltk_data...\n       |   Unzipping corpora/rte.zip.\n       | Downloading package semcor to /home/jovyan/nltk_data...\n       | Downloading package senseval to /home/jovyan/nltk_data...\n       |   Unzipping corpora/senseval.zip.\n       | Downloading package sentiwordnet to /home/jovyan/nltk_data...\n       |   Unzipping corpora/sentiwordnet.zip.\n       | Downloading package sentence_polarity to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/sentence_polarity.zip.\n       | Downloading package shakespeare to /home/jovyan/nltk_data...\n       |   Unzipping corpora/shakespeare.zip.\n       | Downloading package sinica_treebank to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/sinica_treebank.zip.\n       | Downloading package smultron to /home/jovyan/nltk_data...\n       |   Unzipping corpora/smultron.zip.\n       | Downloading package state_union to /home/jovyan/nltk_data...\n       |   Unzipping corpora/state_union.zip.\n       | Downloading package stopwords to /home/jovyan/nltk_data...\n       |   Unzipping corpora/stopwords.zip.\n       | Downloading package subjectivity to /home/jovyan/nltk_data...\n       |   Unzipping corpora/subjectivity.zip.\n       | Downloading package swadesh to /home/jovyan/nltk_data...\n       |   Unzipping corpora/swadesh.zip.\n       | Downloading package switchboard to /home/jovyan/nltk_data...\n       |   Unzipping corpora/switchboard.zip.\n       | Downloading package timit to /home/jovyan/nltk_data...\n       |   Unzipping corpora/timit.zip.\n       | Downloading package toolbox to /home/jovyan/nltk_data...\n       |   Unzipping corpora/toolbox.zip.\n       | Downloading package treebank to /home/jovyan/nltk_data...\n       |   Unzipping corpora/treebank.zip.\n       | Downloading package twitter_samples to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/twitter_samples.zip.\n       | Downloading package udhr to /home/jovyan/nltk_data...\n       |   Unzipping corpora/udhr.zip.\n       | Downloading package udhr2 to /home/jovyan/nltk_data...\n       |   Unzipping corpora/udhr2.zip.\n       | Downloading package unicode_samples to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/unicode_samples.zip.\n       | Downloading package universal_treebanks_v20 to\n       |     /home/jovyan/nltk_data...\n","name":"stderr"},{"output_type":"stream","text":"       | Downloading package verbnet to /home/jovyan/nltk_data...\n       |   Unzipping corpora/verbnet.zip.\n       | Downloading package verbnet3 to /home/jovyan/nltk_data...\n       |   Unzipping corpora/verbnet3.zip.\n       | Downloading package webtext to /home/jovyan/nltk_data...\n       |   Unzipping corpora/webtext.zip.\n       | Downloading package wordnet to /home/jovyan/nltk_data...\n       |   Unzipping corpora/wordnet.zip.\n       | Downloading package wordnet_ic to /home/jovyan/nltk_data...\n       |   Unzipping corpora/wordnet_ic.zip.\n       | Downloading package words to /home/jovyan/nltk_data...\n       |   Unzipping corpora/words.zip.\n       | Downloading package ycoe to /home/jovyan/nltk_data...\n       |   Unzipping corpora/ycoe.zip.\n       | Downloading package rslp to /home/jovyan/nltk_data...\n       |   Unzipping stemmers/rslp.zip.\n       | Downloading package maxent_treebank_pos_tagger to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n       | Downloading package universal_tagset to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping taggers/universal_tagset.zip.\n       | Downloading package maxent_ne_chunker to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping chunkers/maxent_ne_chunker.zip.\n       | Downloading package punkt to /home/jovyan/nltk_data...\n       |   Unzipping tokenizers/punkt.zip.\n       | Downloading package book_grammars to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping grammars/book_grammars.zip.\n       | Downloading package sample_grammars to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping grammars/sample_grammars.zip.\n       | Downloading package spanish_grammars to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping grammars/spanish_grammars.zip.\n       | Downloading package basque_grammars to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping grammars/basque_grammars.zip.\n       | Downloading package large_grammars to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping grammars/large_grammars.zip.\n       | Downloading package tagsets to /home/jovyan/nltk_data...\n       |   Unzipping help/tagsets.zip.\n       | Downloading package snowball_data to\n       |     /home/jovyan/nltk_data...\n       | Downloading package bllip_wsj_no_aux to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping models/bllip_wsj_no_aux.zip.\n       | Downloading package word2vec_sample to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping models/word2vec_sample.zip.\n       | Downloading package panlex_swadesh to\n       |     /home/jovyan/nltk_data...\n       | Downloading package mte_teip5 to /home/jovyan/nltk_data...\n       |   Unzipping corpora/mte_teip5.zip.\n       | Downloading package averaged_perceptron_tagger to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n       | Downloading package averaged_perceptron_tagger_ru to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n       | Downloading package perluniprops to /home/jovyan/nltk_data...\n       |   Unzipping misc/perluniprops.zip.\n       | Downloading package nonbreaking_prefixes to\n       |     /home/jovyan/nltk_data...\n       |   Unzipping corpora/nonbreaking_prefixes.zip.\n       | Downloading package vader_lexicon to\n       |     /home/jovyan/nltk_data...\n       | Downloading package porter_test to /home/jovyan/nltk_data...\n       |   Unzipping stemmers/porter_test.zip.\n       | Downloading package wmt15_eval to /home/jovyan/nltk_data...\n       |   Unzipping models/wmt15_eval.zip.\n       | Downloading package mwa_ppdb to /home/jovyan/nltk_data...\n       |   Unzipping misc/mwa_ppdb.zip.\n       | \n     Done downloading collection all\n","name":"stderr"},{"output_type":"stream","text":"\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\nDownloader> q\n","name":"stdout"},{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nimport os\nimport nltk.corpus","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(nltk.data.find('corpora')))","execution_count":7,"outputs":[{"output_type":"stream","text":"['sentence_polarity', 'timit.zip', 'chat80', 'paradigms.zip', 'unicode_samples', 'twitter_samples', 'semcor.zip', 'city_database', 'unicode_samples.zip', 'wordnet', 'nps_chat', 'treebank.zip', 'genesis', 'omw.zip', 'ycoe', 'alpino', 'pl196x', 'lin_thesaurus.zip', 'nonbreaking_prefixes.zip', 'udhr', 'floresta.zip', 'sentiwordnet.zip', 'sinica_treebank.zip', 'brown', 'treebank', 'mte_teip5', 'words.zip', 'comtrans.zip', 'dolch', 'smultron.zip', 'framenet_v17.zip', 'twitter_samples.zip', 'subjectivity.zip', 'verbnet.zip', 'switchboard.zip', 'europarl_raw', 'ptb', 'brown.zip', 'qc', 'alpino.zip', 'opinion_lexicon', 'problem_reports', 'machado.zip', 'udhr.zip', 'stopwords', 'cmudict', 'abc.zip', 'indian.zip', 'wordnet_ic.zip', 'toolbox', 'lin_thesaurus', 'verbnet3', 'pil', 'inaugural', 'genesis.zip', 'conll2000', 'ppattach', 'movie_reviews.zip', 'movie_reviews', 'ycoe.zip', 'subjectivity', 'wordnet_ic', 'knbc.zip', 'cess_cat', 'paradigms', 'sentiwordnet', 'gazetteers', 'biocreative_ppi.zip', 'pros_cons', 'brown_tei', 'kimmo', 'ieer', 'city_database.zip', 'crubadan.zip', 'senseval.zip', 'nps_chat.zip', 'toolbox.zip', 'ieer.zip', 'product_reviews_2.zip', 'biocreative_ppi', 'udhr2', 'panlex_swadesh.zip', 'opinion_lexicon.zip', 'product_reviews_1.zip', 'mac_morpho', 'conll2002.zip', 'shakespeare', 'conll2002', 'state_union', 'sinica_treebank', 'dependency_treebank', 'pl196x.zip', 'gutenberg', 'sentence_polarity.zip', 'smultron', 'verbnet', 'udhr2.zip', 'framenet_v15', 'wordnet.zip', 'product_reviews_2', 'conll2000.zip', 'ppattach.zip', 'pil.zip', 'stopwords.zip', 'europarl_raw.zip', 'propbank.zip', 'problem_reports.zip', 'rte.zip', 'product_reviews_1', 'indian', 'masc_tagged.zip', 'shakespeare.zip', 'brown_tei.zip', 'names', 'senseval', 'inaugural.zip', 'mac_morpho.zip', 'dependency_treebank.zip', 'comparative_sentences.zip', 'cmudict.zip', 'webtext.zip', 'webtext', 'framenet_v17', 'kimmo.zip', 'dolch.zip', 'chat80.zip', 'reuters.zip', 'pros_cons.zip', 'abc', 'gazetteers.zip', 'cess_esp.zip', 'universal_treebanks_v20.zip', 'framenet_v15.zip', 'cess_esp', 'nombank.1.0.zip', 'names.zip', 'conll2007.zip', 'nonbreaking_prefixes', 'comparative_sentences', 'words', 'ptb.zip', 'verbnet3.zip', 'crubadan', 'swadesh', 'rte', 'swadesh.zip', 'switchboard', 'floresta', 'jeita.zip', 'mte_teip5.zip', 'state_union.zip', 'gutenberg.zip', 'timit', 'omw', 'cess_cat.zip', 'qc.zip']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import brown\nbrown.words()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.corpus.gutenberg.fileids()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"['austen-emma.txt',\n 'austen-persuasion.txt',\n 'austen-sense.txt',\n 'bible-kjv.txt',\n 'blake-poems.txt',\n 'bryant-stories.txt',\n 'burgess-busterbrown.txt',\n 'carroll-alice.txt',\n 'chesterton-ball.txt',\n 'chesterton-brown.txt',\n 'chesterton-thursday.txt',\n 'edgeworth-parents.txt',\n 'melville-moby_dick.txt',\n 'milton-paradise.txt',\n 'shakespeare-caesar.txt',\n 'shakespeare-hamlet.txt',\n 'shakespeare-macbeth.txt',\n 'whitman-leaves.txt']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"hamlet=nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\nhamlet","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for word in hamlet[:500]:\n    print(word, sep=' ',end=' ')\n","execution_count":13,"outputs":[{"output_type":"stream","text":"[ The Tragedie of Hamlet by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Barnardo and Francisco two Centinels . Barnardo . Who ' s there ? Fran . Nay answer me : Stand & vnfold your selfe Bar . Long liue the King Fran . Barnardo ? Bar . He Fran . You come most carefully vpon your houre Bar . ' Tis now strook twelue , get thee to bed Francisco Fran . For this releefe much thankes : ' Tis bitter cold , And I am sicke at heart Barn . Haue you had quiet Guard ? Fran . Not a Mouse stirring Barn . Well , goodnight . If you do meet Horatio and Marcellus , the Riuals of my Watch , bid them make hast . Enter Horatio and Marcellus . Fran . I thinke I heare them . Stand : who ' s there ? Hor . Friends to this ground Mar . And Leige - men to the Dane Fran . Giue you good night Mar . O farwel honest Soldier , who hath relieu ' d you ? Fra . Barnardo ha ' s my place : giue you goodnight . Exit Fran . Mar . Holla Barnardo Bar . Say , what is Horatio there ? Hor . A peece of him Bar . Welcome Horatio , welcome good Marcellus Mar . What , ha ' s this thing appear ' d againe to night Bar . I haue seene nothing Mar . Horatio saies , ' tis but our Fantasie , And will not let beleefe take hold of him Touching this dreaded sight , twice seene of vs , Therefore I haue intreated him along With vs , to watch the minutes of this Night , That if againe this Apparition come , He may approue our eyes , and speake to it Hor . Tush , tush , ' twill not appeare Bar . Sit downe a - while , And let vs once againe assaile your eares , That are so fortified against our Story , What we two Nights haue seene Hor . Well , sit we downe , And let vs heare Barnardo speake of this Barn . Last night of all , When yond same Starre that ' s Westward from the Pole Had made his course t ' illume that part of Heauen Where now it burnes , Marcellus and my selfe , The Bell then beating one Mar . Peace , breake thee of : Enter the Ghost . Looke where it comes againe Barn . In the same figure , like the King that ' s dead Mar . Thou art a Scholler ; speake to it Horatio Barn . Lookes it not like the King ? Marke it Horatio Hora . Most like : It harrowes me with fear & wonder Barn . It would be spoke too Mar . Question it Horatio Hor . What art ","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(hamlet)","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"nltk.corpus.reader.util.StreamBackedCorpusView"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"AI =\"\"\"According to the father of Artificial intelligence, John McCarthy, it is The science and engineering \"\"\"\n","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(AI)","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"str"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import word_tokenize","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AI_tokens = word_tokenize(AI)\nAI_tokens","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"['According',\n 'to',\n 'the',\n 'father',\n 'of',\n 'Artificial',\n 'intelligence',\n ',',\n 'John',\n 'McCarthy',\n ',',\n 'it',\n 'is',\n 'The',\n 'science',\n 'and',\n 'engineering']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(AI_tokens)","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"17"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.probability import FreqDist\nfqdst = FreqDist()\n","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for word in AI_tokens:\n    fqdst[word.lower()]+=1\nfqdst    ","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"FreqDist({'the': 2, ',': 2, 'according': 1, 'to': 1, 'father': 1, 'of': 1, 'artificial': 1, 'intelligence': 1, 'john': 1, 'mccarthy': 1, ...})"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fqdst['the']","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"2"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(fqdst)","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"15"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fqdst_top10 = fqdst.most_common(10)\nfqdst_top10","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"[('the', 2),\n (',', 2),\n ('according', 1),\n ('to', 1),\n ('father', 1),\n ('of', 1),\n ('artificial', 1),\n ('intelligence', 1),\n ('john', 1),\n ('mccarthy', 1)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import blankline_tokenize\nAI_blank = blankline_tokenize(AI)\nlen(AI_blank)","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"1"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.util import bigrams, trigrams,ngrams","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"string = \"The best and the most beautiful things in the world cannot be seen or even touched, they must be felt with the heart\"\nquotes_tokens = nltk.word_tokenize(string)\nquotes_tokens","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"['The',\n 'best',\n 'and',\n 'the',\n 'most',\n 'beautiful',\n 'things',\n 'in',\n 'the',\n 'world',\n 'can',\n 'not',\n 'be',\n 'seen',\n 'or',\n 'even',\n 'touched',\n ',',\n 'they',\n 'must',\n 'be',\n 'felt',\n 'with',\n 'the',\n 'heart']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"quotes_bigrams = list(nltk.bigrams(quotes_tokens))\nquotes_bigrams","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"[('The', 'best'),\n ('best', 'and'),\n ('and', 'the'),\n ('the', 'most'),\n ('most', 'beautiful'),\n ('beautiful', 'things'),\n ('things', 'in'),\n ('in', 'the'),\n ('the', 'world'),\n ('world', 'can'),\n ('can', 'not'),\n ('not', 'be'),\n ('be', 'seen'),\n ('seen', 'or'),\n ('or', 'even'),\n ('even', 'touched'),\n ('touched', ','),\n (',', 'they'),\n ('they', 'must'),\n ('must', 'be'),\n ('be', 'felt'),\n ('felt', 'with'),\n ('with', 'the'),\n ('the', 'heart')]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"quotes_ngrams = list(nltk.ngrams(quotes_tokens, 5))\nquotes_ngrams","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"[('The', 'best', 'and', 'the', 'most'),\n ('best', 'and', 'the', 'most', 'beautiful'),\n ('and', 'the', 'most', 'beautiful', 'things'),\n ('the', 'most', 'beautiful', 'things', 'in'),\n ('most', 'beautiful', 'things', 'in', 'the'),\n ('beautiful', 'things', 'in', 'the', 'world'),\n ('things', 'in', 'the', 'world', 'can'),\n ('in', 'the', 'world', 'can', 'not'),\n ('the', 'world', 'can', 'not', 'be'),\n ('world', 'can', 'not', 'be', 'seen'),\n ('can', 'not', 'be', 'seen', 'or'),\n ('not', 'be', 'seen', 'or', 'even'),\n ('be', 'seen', 'or', 'even', 'touched'),\n ('seen', 'or', 'even', 'touched', ','),\n ('or', 'even', 'touched', ',', 'they'),\n ('even', 'touched', ',', 'they', 'must'),\n ('touched', ',', 'they', 'must', 'be'),\n (',', 'they', 'must', 'be', 'felt'),\n ('they', 'must', 'be', 'felt', 'with'),\n ('must', 'be', 'felt', 'with', 'the'),\n ('be', 'felt', 'with', 'the', 'heart')]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import PorterStemmer\npost = PorterStemmer()","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"post.stem(\"having\")","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"'have'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"post.stem(\"lingual\")","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"'lingual'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"post.stem(\"Lemmatization\")","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"'lemmat'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"post.stem(\"Acropolis\")","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"'acropoli'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"post.stem(\"Aritra\")","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"'aritra'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"post.stem(\"Nematoda\")","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"'nematoda'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"words_to_stem = ['give','giving','given','gave']\nfor words in words_to_stem:\n    print(words + \":\" +post.stem(words))\n    ","execution_count":43,"outputs":[{"output_type":"stream","text":"give:give\ngiving:give\ngiven:given\ngave:gave\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import LancasterStemmer\nlst=LancasterStemmer()\nfor words in words_to_stem:\n    print(words+ \":\" +lst.stem(words))","execution_count":45,"outputs":[{"output_type":"stream","text":"give:giv\ngiving:giv\ngiven:giv\ngave:gav\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import SnowballStemmer\nsbst=SnowballStemmer('english')\n","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for words in words_to_stem:\n    print(words+ \":\" +sbst.stem(words))","execution_count":48,"outputs":[{"output_type":"stream","text":"give:give\ngiving:give\ngiven:given\ngave:gave\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import wordnet\nfrom nltk.stem import WordNetLemmatizer\nword_len=WordNetLemmatizer()","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_len.lemmatize('corpora')","execution_count":51,"outputs":[{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"'corpus'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_len.lemmatize('Cloud')","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"'Cloud'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_len.lemmatize('Infinity')","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"'Infinity'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for words in words_to_stem:\n    print(words+ \":\" +word_len.lemmatize(words))","execution_count":56,"outputs":[{"output_type":"stream","text":"give:give\ngiving:giving\ngiven:given\ngave:gave\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords.words('english')","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"['i',\n 'me',\n 'my',\n 'myself',\n 'we',\n 'our',\n 'ours',\n 'ourselves',\n 'you',\n \"you're\",\n \"you've\",\n \"you'll\",\n \"you'd\",\n 'your',\n 'yours',\n 'yourself',\n 'yourselves',\n 'he',\n 'him',\n 'his',\n 'himself',\n 'she',\n \"she's\",\n 'her',\n 'hers',\n 'herself',\n 'it',\n \"it's\",\n 'its',\n 'itself',\n 'they',\n 'them',\n 'their',\n 'theirs',\n 'themselves',\n 'what',\n 'which',\n 'who',\n 'whom',\n 'this',\n 'that',\n \"that'll\",\n 'these',\n 'those',\n 'am',\n 'is',\n 'are',\n 'was',\n 'were',\n 'be',\n 'been',\n 'being',\n 'have',\n 'has',\n 'had',\n 'having',\n 'do',\n 'does',\n 'did',\n 'doing',\n 'a',\n 'an',\n 'the',\n 'and',\n 'but',\n 'if',\n 'or',\n 'because',\n 'as',\n 'until',\n 'while',\n 'of',\n 'at',\n 'by',\n 'for',\n 'with',\n 'about',\n 'against',\n 'between',\n 'into',\n 'through',\n 'during',\n 'before',\n 'after',\n 'above',\n 'below',\n 'to',\n 'from',\n 'up',\n 'down',\n 'in',\n 'out',\n 'on',\n 'off',\n 'over',\n 'under',\n 'again',\n 'further',\n 'then',\n 'once',\n 'here',\n 'there',\n 'when',\n 'where',\n 'why',\n 'how',\n 'all',\n 'any',\n 'both',\n 'each',\n 'few',\n 'more',\n 'most',\n 'other',\n 'some',\n 'such',\n 'no',\n 'nor',\n 'not',\n 'only',\n 'own',\n 'same',\n 'so',\n 'than',\n 'too',\n 'very',\n 's',\n 't',\n 'can',\n 'will',\n 'just',\n 'don',\n \"don't\",\n 'should',\n \"should've\",\n 'now',\n 'd',\n 'll',\n 'm',\n 'o',\n 're',\n 've',\n 'y',\n 'ain',\n 'aren',\n \"aren't\",\n 'couldn',\n \"couldn't\",\n 'didn',\n \"didn't\",\n 'doesn',\n \"doesn't\",\n 'hadn',\n \"hadn't\",\n 'hasn',\n \"hasn't\",\n 'haven',\n \"haven't\",\n 'isn',\n \"isn't\",\n 'ma',\n 'mightn',\n \"mightn't\",\n 'mustn',\n \"mustn't\",\n 'needn',\n \"needn't\",\n 'shan',\n \"shan't\",\n 'shouldn',\n \"shouldn't\",\n 'wasn',\n \"wasn't\",\n 'weren',\n \"weren't\",\n 'won',\n \"won't\",\n 'wouldn',\n \"wouldn't\"]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(stopwords.words('english'))","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"179"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fqdst_top10","execution_count":61,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"[('the', 2),\n (',', 2),\n ('according', 1),\n ('to', 1),\n ('father', 1),\n ('of', 1),\n ('artificial', 1),\n ('intelligence', 1),\n ('john', 1),\n ('mccarthy', 1)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\npunctuations=re.compile(r'[-.?!,:;()|0-9]')","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"post_punctuations=[]\nfor words in AI_tokens:\n    word=punctuations.sub(\"\",words)\n    if len(word)>0:\n        post_punctuations.append(word)","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent=\"John is a natural when it comes to singing\"\nsent_tokens = word_tokenize(sent)","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for token in sent_tokens:\n    print(nltk.pos_tag([token]))","execution_count":68,"outputs":[{"output_type":"stream","text":"[('John', 'NNP')]\n[('is', 'VBZ')]\n[('a', 'DT')]\n[('natural', 'JJ')]\n[('when', 'WRB')]\n[('it', 'PRP')]\n[('comes', 'VBZ')]\n[('to', 'TO')]\n[('singing', 'VBG')]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk import ne_chunk\n","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NE_sent= \"The Indian Prime Minister stays in Delhi\"","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NE_tokens = word_tokenize(NE_sent)\nNE_tags = nltk.pos_tag(NE_tokens)","execution_count":72,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NE_NER = ne_chunk(NE_tags)\nprint(NE_NER)","execution_count":73,"outputs":[{"output_type":"stream","text":"(S\n  The/DT\n  (GPE Indian/JJ)\n  Prime/NNP\n  Minister/NNP\n  stays/VBZ\n  in/IN\n  (GPE Delhi/NNP))\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":""}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}